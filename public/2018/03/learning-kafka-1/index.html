<!DOCTYPE html>
<html lang="">
  <head>
    
<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,minimum-scale=1,maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />


<meta name="description" content="这是水滴产品团队面向 Scala 的中文技术博客，原创 Scala 文章、教程。"/>


<meta name="keywords" content="scala,scala 教程,scala 文章,scala 中文,scala 社区" />

<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>



  <link rel="alternate" href="/default" title="Scala Cool">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=1.1" />



<link rel="canonical" href="http://scala.cool/2018/03/learning-kafka-1/"/>


<meta name="description" content="我们在学习一个东西的时候，往往只有真正了解它背后的含义，才能一步一步的掌握它，直到运筹帷幄。对于 Kafka 来说，本文就基于官方文档来初探一下 Kafka，正如官方文档而言，且读且珍惜。">
<meta name="keywords" content="^Godpan,Kafka,~Kafka 系列,分布式系统">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka 学习笔记（一） ：为什么需要 Kafka？">
<meta property="og:url" content="http://scala.cool/2018/03/learning-kafka-1/index.html">
<meta property="og:site_name" content="Scala Cool">
<meta property="og:description" content="我们在学习一个东西的时候，往往只有真正了解它背后的含义，才能一步一步的掌握它，直到运筹帷幄。对于 Kafka 来说，本文就基于官方文档来初探一下 Kafka，正如官方文档而言，且读且珍惜。">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://scala.cool/images/2018/03/simple-message-system.png">
<meta property="og:image" content="http://scala.cool/images/2018/03/simple-message-queue-system.png">
<meta property="og:image" content="http://scala.cool/images/2018/03/message-system.png">
<meta property="og:image" content="http://scala.cool/images/2018/03/kafka-apis.png">
<meta property="og:image" content="http://scala.cool/images/2018/03/log-anatomy.png">
<meta property="og:image" content="http://scala.cool/images/2018/03/log-consumer.png">
<meta property="og:image" content="http://scala.cool/images/2018/03/consumer-groups.png">
<meta property="og:updated_time" content="2018-03-14T01:56:36.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Kafka 学习笔记（一） ：为什么需要 Kafka？">
<meta name="twitter:description" content="我们在学习一个东西的时候，往往只有真正了解它背后的含义，才能一步一步的掌握它，直到运筹帷幄。对于 Kafka 来说，本文就基于官方文档来初探一下 Kafka，正如官方文档而言，且读且珍惜。">
<meta name="twitter:image" content="http://scala.cool/images/2018/03/simple-message-system.png">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=1.1" />
<link href='https://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet'>





<script type="text/javascript">
  var themeConfig = {
    fancybox: {
      enable: false
    },
  };
</script>




  
  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?dfcb338d3c2ed49b6a5e26760868e19f";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




    <title> Kafka 学习笔记（一） ：为什么需要 Kafka？ - Scala Cool </title>
  </head>

  <body>
    <div id="page">
      <header id="masthead" ><div class="site-header-inner">
    <h1 class="site-title ">
        <a href="/." class="logo">Scala Cool</a>
    </h1>
    <nav id="nav-top">
        
            <ul id="menu-top" class="nav-top-items">
                
                    <li class="menu-item">
                        <a href="https://jianshiapp.com/circles/108511">
                            
                            
                                技术圈
                            
                        </a>
                    </li>
                
                    <li class="menu-item">
                        <a href="http://news.scala.cool">
                            
                            
                                社区动态
                            
                        </a>
                    </li>
                
                    <li class="menu-item">
                        <a href="https://scala.cool/2017/03/hello-scala/">
                            
                            
                                关于
                            
                        </a>
                    </li>
                
            </ul>
        
  </nav>
</div>

      </header>
      <div id="content">
        
    <div id="primary">
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          Kafka 学习笔记（一） ：为什么需要 Kafka？
        
      </h1>

      <time class="post-time">
          3月14日
      </time>
      
        <span class="author-split">|</span>
        <span class="author-info">
          by <span class="_author-text-holder" data-author="Godpan"></span>
        </span>
      
      
        <span class="_author-avatar-holder" data-author="Godpan"></span>
      
    </header>



    
            <div class="post-content">
            <p>我们在学习一个东西的时候，往往只有真正了解它背后的含义，才能一步一步的掌握它，直到运筹帷幄。对于Kafka来说，我也是一个小白，本篇文章我就以一个小白的角度来初探一下Kafka，本篇文章基于官方文档，顺便说一句官方文档真的很重要，且读且珍惜。</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>Kafka最早是由LinkedIn公司开发的，作为其自身业务消息处理的基础，后LinkedIn公司将Kafka捐赠给Apache，现在已经成为Apache的一个顶级项目了，Kafka作为一个高吞吐的分布式的消息系统，目前已经被很多公司应用在实际的业务中了，并且与许多数据处理框架相结合，比如Hadoop，Spark等。</p>
<h3 id="消息系统"><a href="#消息系统" class="headerlink" title="消息系统"></a>消息系统</h3><p>在实际的业务需求中，我们需要处理各种各样的消息，比如Page View,日志，请求等，那么一个好的消息系统应该拥有哪些功能呢？</p>
<ul>
<li>拥有消息发布和订阅的功能，类似于消息队列或者企业消息传送系统；</li>
<li>能存储消息流，并具备容错性；</li>
<li>能够实时的处理消息；</li>
</ul>
<p>以上3点是作为一个好的消息系统的最基本的能力。</p>
<p>那么Kafka为什么会诞生呢？</p>
<p>其实在我们工作中，相信有很多也接触过消息队列，甚至自己也写过简单的消息系统，它最基本应该拥有发布/订阅的功能，如下图所示：</p>
<p><img src="/images/2018/03/simple-message-system.png" alt="simple-message-system"></p>
<p>其中消费者A与消费者B都订阅了消息源A和消息源B，这种模式很简单，但是相对来说也有弊端，比如以下两点：</p>
<ul>
<li>该模式下消费者需要实时去处理消息，因为这里消息源和消费者都不会维护一个消息队列（维护代价太大），这将会导致消费者若是暂时没有能力消费，则消息会丢失，当然也就不能获得历史的消息；</li>
<li>消息源需要维护原本不属于它的工作，比如维护订阅者（消费者）的信息，向多个消费者发送消息，亦或者有些还需要处理消息反馈，这是原本纯粹的消息源就会变得越来越复杂；</li>
</ul>
<p>当然这些问题都是可以改进的，比如我们可以在消息源和消费者中间增加一个消息队列，如下图所示：</p>
<p><img src="/images/2018/03/simple-message-queue-system.png" alt="simple-message-queue-system"></p>
<p>从图中我们可以看出，现在消息源只需要将消息发送到消息队列中就行，至于其他就将给消息队列去完成，我们可以在消息队列持久化消息，主动推消息给已经订阅了该消息队列的消费者，那么这种模式还有什么缺点吗？</p>
<p>答案是有，上图只是两个消息队列，我们维护起来并不困难，但是如果有成百上千个呢？那不得gg，其实我们可以发现，消息队列的功能都很类似，无非就是持久化消息，推送消息，给出反馈等功能，结构也非常类似，主要是消息内容，当然如果要通用化，消息结构也要尽可能通用化，与具体平台具体语言无关，比如用JSON格式等，所有我们可以演变出以下的消息系统：</p>
<p><img src="/images/2018/03/message-system.png" alt="message-system"></p>
<p>这个方式看起来只是把上面的队列合并到了一起，其实并不那么简单，因为这个消息队列集合要具备以下几个功能：</p>
<ul>
<li>能统一管理所有的消息队列，不是特殊需求不需要开发者自己去维护；</li>
<li>高效率的存储消息；</li>
<li>消费者能快速的找到想要消费的消息；</li>
</ul>
<p>当然这些只是最基本的功能，还有比如多节点容错，数据备份等，一个好的消息系统需要处理的东西非常多，很庆幸，Kafka帮我们做到了。</p>
<h3 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h3><p>在具体了解Kafka的细节前，我们先来看一下它的一些基本概念：</p>
<ul>
<li>Kafka是运行在一个集群上，所以它可以拥有一个或多个服务节点；</li>
<li>Kafka集群将消息存储在特定的文件中，对外表现为Topics；</li>
<li>每条消息记录都包含一个key,消息内容以及时间戳；</li>
</ul>
<p>从上面几点我们大致可以推测Kafka是一个分布式的消息存储系统，那么它就仅仅这么点功能吗，我们继续看下面。</p>
<p>Kafka为了拥有更强大的功能，提供了四大核心接口：</p>
<ul>
<li>Producer API允许了应用可以向Kafka中的topics发布消息；</li>
<li>Consumer API允许了应用可以订阅Kafka中的topics,并消费消息；</li>
<li>Streams API允许应用可以作为消息流的处理者，比如可以从topicA中消费消息，处理的结果发布到topicB中；</li>
<li>Connector API提供Kafka与现有的应用或系统适配功能，比如与数据库连接器可以捕获表结构的变化；</li>
</ul>
<p>它们与Kafka集群的关系可以用下图表示：</p>
<p><img src="/images/2018/03/kafka-apis.png" alt="kafka-apis"></p>
<p>在了解了Kafka的一些基本概念后，我们具体来看看它的一些组成部分。</p>
<h4 id="Topics"><a href="#Topics" class="headerlink" title="Topics"></a>Topics</h4><p>顾名思义Topics是一些主题的集合，更通俗的说Topic就像一个消息队列，生产者可以向其写入消息，消费者可以从中读取消息，一个Topic支持多个生产者或消费者同时订阅它，所以其扩展性很好。Topic又可以由一个或多个partition（分区）组成，比如下图：</p>
<p><img src="/images/2018/03/log-anatomy.png" alt="log-anatomy"></p>
<p>其中每个partition中的消息是有序的，但相互之间的顺序就不能保证了，若Topic有多个partition，生产者的消息可以指定或者由系统根据算法分配到指定分区，若你需要所有消息都是有序的，那么你最好只用一个分区。另外partition支持消息位移读取，消息位移有消费者自身管理，比如下图：</p>
<p><img src="/images/2018/03/log-consumer.png" alt="log-consumer"></p>
<p>由上图可以看出，不同消费者对同一分区的消息读取互不干扰，消费者可以通过设置消息位移（offset）来控制自己想要获取的数据，比如可以从头读取，最新数据读取，重读读取等功能。</p>
<p>关于Topic的分区策略以及与消费者间平衡后续文章会继续深入讲解。</p>
<h4 id="Distribution"><a href="#Distribution" class="headerlink" title="Distribution"></a>Distribution</h4><p>上文说到过，Kafka是一个分布式的消息系统，所以当我们配置了多个Kafka Server节点后，它就拥有分布式的能力，比如容错等，partition会被分布在各个Server节点上，同时它们中间又有一个leader，它会处理所有的读写请求，其他followers会复制leader上的数据信息，一旦当leader因为某些故障而无法提供服务后，就会有一个follower被推举出来成为新的leader来处理这些请求。</p>
<h4 id="Geo-Replication"><a href="#Geo-Replication" class="headerlink" title="Geo-Replication"></a>Geo-Replication</h4><p>异地备份是作为主流分布式系统的基础功能，用于集群中数据的备份和恢复，Kafka利用MirrorMaker来实现这个功能，用户只需简单的进行相应配置即可。</p>
<h4 id="Producers"><a href="#Producers" class="headerlink" title="Producers"></a>Producers</h4><p>Producers作为消息的生产者，可以自己指定将消息发布到订阅Topic中的指定分区，策略可以自己指定，比如语义或者结构类似的消息发布在同一分区，当然也可以由系统循环发布在每一个分区上。</p>
<h4 id="Consumers"><a href="#Consumers" class="headerlink" title="Consumers"></a>Consumers</h4><p>Consumers是一群消费者的集合，可以称之为消费者组，是一种更高层次的的抽象，向Topic订阅消费消息的单位是Consumers，当然它其中也可以只有一个消费者（consumer）。下面是关于consumer的两条原则：</p>
<ul>
<li>假如所有消费者都在同一个消费者组中，那么它们将协同消费订阅Topic的部分消息（根据分区与消费者的数量分配），保存负载平衡；</li>
<li>假如所有消费者都在不同的消费者组中，并且订阅了同个Topic，那么它们将可以消费Topic的所有消息；</li>
</ul>
<p>下面是一个简单的例子，帮助大家理解：</p>
<p><img src="/images/2018/03/consumer-groups.png" alt="consumer-groups"></p>
<p>上图中有两个Server节点，有一个Topic被分为四个分区（P0-P4)分别被分配在两个节点上，另外还有两个消费者组（GA，GB），其中GA有两个消费者实例，GB有四个消费者实例。</p>
<p>从图中我们可以看出，首先订阅Topic的单位是消费者组，另外我们发现Topic中的消息根据一定规则将消息推送给具体消费者，主要原则如下：</p>
<ul>
<li>若消费者数小于partition数，且消费者数为一个，那么它就消费所有消息；</li>
<li>若消费者数小于partition数，假设消费者数为N，partition数为M，那么每个消费者能消费的分区数为M/N或M/N+1；</li>
<li>若消费者数等于partition数，那么每个消费者都会均等分配到一个分区的消息；</li>
<li>若消费者数大于partition数，则将会出现部分消费者得不到消息分区，出现空闲的情况；</li>
</ul>
<p>总的来说，Kafka会根据消费者组的情况均衡分配消息，比如有消息着实例宕机，亦或者有新的消费者加入等情况。</p>
<h4 id="Guarantees"><a href="#Guarantees" class="headerlink" title="Guarantees"></a>Guarantees</h4><p>kafka作为一个高水准的系统，提供了以下的保证：</p>
<ul>
<li>消息的添加是有序的，生产者越早向订阅的Topic发送的消息，会更早的被添加到Topic中，当然它们可能被分配到不同的分区；</li>
<li>消费者在消费Topic分区中的消息时是有序的；</li>
<li>对于有N个复制节点的Topic，系统可以最多容忍N-1个节点发生故障，而不丢失任何提交给该Topic的消息丢失；</li>
</ul>
<p>相关这些点的细节，我准备再后续文章中再慢慢深入。</p>
<h3 id="Kafka-as-a-Messaging-System"><a href="#Kafka-as-a-Messaging-System" class="headerlink" title="Kafka as a Messaging System"></a>Kafka as a Messaging System</h3><p>说了这么多，前面也讲了消息系统的演变过程，那么Kafka相比其他的消息系统优势具体在哪里？<br>传统的消息系统模型主要有两种：消息队列和发布/订阅。</p>
<p>1.消息队列</p>
<table>
<thead>
<tr>
<th>特性</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>表现形式</td>
<td>一组消费者从消息队列中获取消息，消息会被推送给组中的某一个消费者</td>
</tr>
<tr>
<td>优势</td>
<td>水平扩展，可以将消息数据分开处理</td>
</tr>
<tr>
<td>劣势</td>
<td>消息队列不是多用户的，当一条消息记录被一个进程读取后，消息便会丢失</td>
</tr>
</tbody>
</table>
<p>2.发布/订阅</p>
<table>
<thead>
<tr>
<th>特性</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>表现形式</td>
<td>消息会广播发送给所有消费者</td>
</tr>
<tr>
<td>优势</td>
<td>可以多进程共享消息</td>
</tr>
<tr>
<td>劣势</td>
<td>每个消费者都会获得所有消息，无法通过添加消费进程提高处理效率</td>
</tr>
</tbody>
</table>
<p>从上面两个表中可以看出两种传统的消息系统模型的优缺点，所以Kafka在前人的肩膀上进行了优化，吸收他们的优点，主要体现在以下两方面：</p>
<ul>
<li>通过Topic方式来达到消息队列的功能</li>
<li>通过消费者组这种方式来达到发布/订阅的功能</li>
</ul>
<p>Kafka通过结合这两点（这两点的具体描述查看上面章节），完美的解决了它们两者模式的缺点。</p>
<h3 id="Kafka-as-a-Storage-System"><a href="#Kafka-as-a-Storage-System" class="headerlink" title="Kafka as a Storage System"></a>Kafka as a Storage System</h3><p>存储消息也是消息系统的一大功能，Kafka相对普通的消息队列存储来说，它的表现实在好的太多，首先Kafka支持写入确认，保证消息写入的正确性和连续性，同时Kafka还会对写入磁盘的数据进行复制备份，来实现容错，另外Kafka对磁盘的使用结构是一致的，就说说不管你的服务器目前磁盘存储的消息数据有多少，它添加消息数据的效率是相同的。</p>
<p>Kafka的存储机制很好的支持消费者可以随意控制自身所需要读取的数据，在很多时候你也可以将Kafka作为一个高性能，低延迟的分布式文件系统。</p>
<h3 id="Kafka-for-Stream-Processing"><a href="#Kafka-for-Stream-Processing" class="headerlink" title="Kafka for Stream Processing"></a>Kafka for Stream Processing</h3><p>Kafka作为一个完美主义代表者，光有普通的读写，存储等功能是不够的，它还提供了实时处理消息流的接口。</p>
<p>很多时候原始的数据并不是我们想要的，我们想要的是经过处理后的数据结果，比如通过一天的搜索数据得出当天的搜索热点等，你可以利用Streams API来实现自己想要的功能，比如从输入Topic中获取数据，然后再发布到具体的输出Topic中。</p>
<p>Kafka的流处理可以解决诸如处理无序数据、数据的复杂转换等问题。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>消息传递、存储、流处理这么功能单一来看确实很普通，但如何把它们完美的结合到一起，就是一种优雅的体现，Kafka做到了这一点。</p>
<p>相比HDFS分布式文件存储系统，虽然它能支持高效存储并且批处理数据，但是它只支持处理过去的历史数据。</p>
<p>相比普通的消息系统来说，虽然能处理现在至未来的数据，但是它并不没有存储历史的数据。</p>
<p>Kafka集众家之所长，使整个系统能兼顾各方面的需求，可以用一个词来说： “完美”！</p>
<p>本文从消息系统的演变讲起，到Kafka的具体组成，最后到Kafka的三大特性，旨在帮助大家能够大概的了解Kafka是什么的，到底有什么作用，当然这只是一个小白的简单理解，如有写得不对的地方，希望大家能够指出，不胜感激。</p>

            </div>
          

    
      <footer class="post-footer">
        <div class="post-tags">
          
            <a href="/tags/Godpan/">^Godpan</a>
          
            <a href="/tags/Kafka/">Kafka</a>
          
            <a href="/tags/Kafka-系列/">~Kafka 系列</a>
          
            <a href="/tags/分布式系统/">分布式系统</a>
          
        </div>

        
        
  <nav class="post-nav">
    
    
      <a class="next" href="/2018/03/reactive-web-applications-4/">
        <span class="next-text nav-default"><译> 响应式 Web 应用（四）</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

        
  <div class="comments" id="comments">
    
    <!--<div style="text-align:center;margin-top: 50px;">
      <a class="btn" href="https://gitter.im/scala_cool/Lobby?source=orgpage" target="_blank">评论这篇文章</a>
    </div>-->
    <div id="gitalk-container"></div>
    <script>
      var Base64={_keyStr:"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=",encode:function(e){var t="";var n,r,i,s,o,u,a;var f=0;e=Base64._utf8_encode(e);while(f<e.length){n=e.charCodeAt(f++);r=e.charCodeAt(f++);i=e.charCodeAt(f++);s=n>>2;o=(n&3)<<4|r>>4;u=(r&15)<<2|i>>6;a=i&63;if(isNaN(r)){u=a=64}else if(isNaN(i)){a=64}t=t+this._keyStr.charAt(s)+this._keyStr.charAt(o)+this._keyStr.charAt(u)+this._keyStr.charAt(a)}return t},decode:function(e){var t="";var n,r,i;var s,o,u,a;var f=0;e=e.replace(/[^A-Za-z0-9+/=]/g,"");while(f<e.length){s=this._keyStr.indexOf(e.charAt(f++));o=this._keyStr.indexOf(e.charAt(f++));u=this._keyStr.indexOf(e.charAt(f++));a=this._keyStr.indexOf(e.charAt(f++));n=s<<2|o>>4;r=(o&15)<<4|u>>2;i=(u&3)<<6|a;t=t+String.fromCharCode(n);if(u!=64){t=t+String.fromCharCode(r)}if(a!=64){t=t+String.fromCharCode(i)}}t=Base64._utf8_decode(t);return t},_utf8_encode:function(e){e=e.replace(/rn/g,"n");var t="";for(var n=0;n<e.length;n++){var r=e.charCodeAt(n);if(r<128){t+=String.fromCharCode(r)}else if(r>127&&r<2048){t+=String.fromCharCode(r>>6|192);t+=String.fromCharCode(r&63|128)}else{t+=String.fromCharCode(r>>12|224);t+=String.fromCharCode(r>>6&63|128);t+=String.fromCharCode(r&63|128)}}return t},_utf8_decode:function(e){var t="";var n=0;var r=c1=c2=0;while(n<e.length){r=e.charCodeAt(n);if(r<128){t+=String.fromCharCode(r);n++}else if(r>191&&r<224){c2=e.charCodeAt(n+1);t+=String.fromCharCode((r&31)<<6|c2&63);n+=2}else{c2=e.charCodeAt(n+1);c3=e.charCodeAt(n+2);t+=String.fromCharCode((r&15)<<12|(c2&63)<<6|c3&63);n+=3}}return t}} 
      var id = Base64.encode(document.getElementsByClassName('post-title')[0].innerHTML.trim())
      id = id.length > 50 && 1520956800000 > 1517414400123 ? id.slice(-50, id.length) : id;
      var gitalk = new Gitalk({
        clientID: '23770b27c2837a5e79a1',
        clientSecret: 'd41712ccd45d7142b31d3b9f355e77f107b29ef2',
        repo: 'scalacool.github.io',
        owner: 'ScalaCool',
        admin: ['yison-dripower'],
        id: id,
        distractionFreeMode: true
      });
      gitalk.render('gitalk-container');
    </script>
  </div>


      </footer>
    
  </article>

    </div>

      </div>

      <footer id="colophon"><span class="copyright-year">
    
        &copy;
    
        2017 -
    
    2018
    <span class="footer-author">ScalaCool.</span>
    <span class="power-by">
        Powered by <a class="hexo-link" href="https://hexo.io/">Hexo</a> and <a class="theme-link" href="https://github.com/frostfan/hexo-theme-polarbear">Polar Bear</a>
    </span>
</span>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>
    


    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  

    <script type="text/javascript" src="/js/src/theme.js?v=1.1"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=1.1"></script>
<script type="text/javascript" src="/js/src/author.js?v=1.1"></script>

  </body>
  <script>
  (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      if (curProtocol === 'https') {
          bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
      }
      else {
          bp.src = 'http://push.zhanzhang.baidu.com/push.js';
      }
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
  })();
  </script>
</html>
